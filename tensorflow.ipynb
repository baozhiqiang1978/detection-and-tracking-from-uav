{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyU7K4tmjiDx"
   },
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Md6bLyJN2Dw"
   },
   "source": [
    "This notebook provide the pipeline I used to detect and track vehicles using [R-FCN](https://arxiv.org/abs/1605.06409) and [MDP](http://cvgl.stanford.edu/projects/MDP_tracking/).  \n",
    "It works with other models similarly simply by using a different [config file](https://github.com/josueBulle/detection-and-tracking-from-uav/tree/master/tf_configs)\n",
    "## Detection\n",
    "Model: R-FCN.  \n",
    "Uses: Tensorflow object_detection api.\n",
    "### Dataset preparation\n",
    "The custom provided dataset is formated for Darknet (Yolo). Tensorflow's implementation uses its own format known as *tf records*. The transformation can be done using the script [createRecords.py](https://github.com/josueBulle/detection-and-tracking-from-uav/blob/master/helpers/createRecords.py).   \n",
    "To avoid this step, the whole dataset converted for tensorflow is available [here](https://drive.google.com/file/d/1gSmlXO3VUulRp_-CxN-H9Gxgu_YOR2qP/view?usp=sharing).\n",
    " (For better handling and parallelization, the dataset is sharded in multiple parts)\n",
    " \n",
    " In either case, the dataset must be linked in the *rfcn.config* file\n",
    "### Training\n",
    "The config file *rfcn.config* contains all the parameters and paths to the training/evaluation datasets.  \n",
    "The file *dataset/label_map.pbtxt*  contains the class names (car, truck, pedestrian etc.).   \n",
    "Tensorboard can be used to monitor the training.\n",
    "### Inference\n",
    "To avoid training, inference can be done from the [trained model](https://drive.google.com/open?id=1S_dpNJe9bFQU4jTA_YGuAC0QUpsvVUll) on this custom dataset.\n",
    "## Tracking\n",
    "Algorithm: MDP  \n",
    "The official source code is available at [MDP_tracking](https://github.com/yuxng/MDP_Tracking).  Uses: Matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8qbk8Fnk21o"
   },
   "source": [
    "# 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYPTyIBVZ8Be"
   },
   "source": [
    "Clone my github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqLDq71Nk4_n"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "# Clone the git project which includes tensorflow's object_detection, slim, pycocotools into /content/detection/\n",
    "\n",
    "cd /content/\n",
    "git clone https://github.com/josueBulle/detection-and-tracking-from-uav.git detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emlO-8kVlEii"
   },
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from google.colab import drive\n",
    "\n",
    "# connect to gDrive\n",
    "drive.mount('/content/drive')\n",
    "!ln -s \"/content/drive/My Drive/\" \"/MyDrive\"\n",
    "\n",
    "# set working dir and export path\n",
    "ROOT = '/content/detection/'\n",
    "os.chdir(ROOT)\n",
    "sys.path.append(ROOT + \"tensorflow\")\n",
    "sys.path.append(ROOT + \"tensorflow/object_detection\")\n",
    "sys.path.append(ROOT + \"tensorflow/slim\")\n",
    "%set_env PYTHONPATH=/env/python:/content/detection/tensorflow:/content/detection/tensorflow/slim:/content/detection/tensorflow/object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdDwTUe1viIC"
   },
   "source": [
    "# 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btmTTrS6_nuX"
   },
   "source": [
    "## 1.1 Retrieve the dataset and pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xFtq5HO3R0w"
   },
   "source": [
    "Tensorflow need a dataset converted into tf_records. (see  [createRecords.py](https://github.com/josueBulle/detection-and-tracking-from-uav/blob/master/helpers/createRecords.py)).\n",
    "\n",
    "\n",
    "This cell can take some minutes, the connection between gDrive and gColab is sometimes slow and the dataset weights ~3 GB.  \n",
    "1. Download the tf_records from gDrive  (assuming the dataset is at the gDrive root directory)\n",
    "2. Download weights trained on the coco dataset (to be used as initial checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQr8lBojvUyY"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "# Download the dataset from gDrive to gColab\n",
    "PATH_TO_TF_RECORDS=\"/MyDrive/aerial_dataset\"\n",
    "cp -a \"$PATH_TO_TF_RECORDS\" /content/detection/dataset/\n",
    "\n",
    "# Download the pre-trained weights\n",
    "mkdir /content/detection/models\n",
    "cd /content/detection/models\n",
    "wget -O tmp.tar.gz http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2018_01_28.tar.gz\n",
    "tar -xzvf tmp.tar.gz\n",
    "rm tmp.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsActO4n9C_X"
   },
   "source": [
    "## 1.2 Training\n",
    "The following cell is optional and allows us to monitor the training using tensorboard. (Requires an evaluation dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bv9GSN54Yl3"
   },
   "outputs": [],
   "source": [
    "# Tensorboard runs locally on gColab. \"ngrok\" allows us to access tensorboard through the internet.\n",
    "\n",
    "LOG_DIR = \"/MyDrive/rfcn-output/\"\n",
    "if not os.path.isdir(LOG_DIR):\n",
    "  os.mkdir(LOG_DIR)\n",
    "\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "!chmod u+x /content/detection/tensorflow/ngrok\n",
    "get_ipython().system_raw('/content/detection/tensorflow/ngrok authtoken 7aXuMYYxjUHa4p2afyRBB_6W9N2KsJQzXmXsqWni7MB')\n",
    "get_ipython().system_raw('/content/detection/tensorflow/ngrok http 6006 &')\n",
    "!sleep 4\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'] + '/#scalars')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LbEYVirOTb7"
   },
   "source": [
    "Start the training using the rfcn.config. SSD and Faster R-CNN configs can be found [here](https://github.com/josueBulle/detection-and-tracking-from-uav/tree/master/tf_configs).  \n",
    "You might need to change the paths to the dataset and weights in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgHCerHT-YLD"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "# The checkpoints and outputs will be saved in the folder designed by the MODEL_DIR variable\n",
    "\n",
    "cd /content/detection/tensorflow/object_detection\n",
    "\n",
    "PIPELINE_CONFIG_PATH=/content/detection/rfcn.config\n",
    "MODEL_DIR=/MyDrive/rfcn-output/\n",
    "NUM_TRAIN_STEPS=80000\n",
    "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
    "\n",
    "python model_main.py \\\n",
    "    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n",
    "    --model_dir=${MODEL_DIR} \\\n",
    "    --num_train_steps=${NUM_TRAIN_STEPS} \\\n",
    "    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n",
    "    --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qakX21NF-JpQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvqcJSSpPAOl"
   },
   "source": [
    "# 3. Export inference graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EBxQ_NbPCwF"
   },
   "source": [
    "Finally, we need to export the trained model for inference (frozen inference graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxW0rWM1PBqd"
   },
   "outputs": [],
   "source": [
    "def export_inference_graph(model_dir, config_path, output_dir):\n",
    "  assert os.path.exists( config_path ), \"File not found : {}\".format(config_path)\n",
    "  assert os.path.isdir( model_dir ), \"Directory does not exists : {}\".format(model_dir)\n",
    "  \n",
    "  if not os.path.isdir( output_dir ):\n",
    "    os.mkdir( output_dir )\n",
    "\n",
    "  # Find the last checkpoint\n",
    "  ls = [ f for f in os.listdir( model_dir ) if f.startswith(\"model.ckpt-\") ]\n",
    "  ls.sort()\n",
    "  best_checkpoint = '.'.join( ls[-1].split('.')[0:2] )\n",
    "  \n",
    "  args = [\"python\", \"/content/detection/tensorflow/object_detection/export_inference_graph.py\"]\n",
    "  args.extend( [\"--input_type\", \"image_tensor\"] )\n",
    "  args.extend( [\"--pipeline_config_path\", config_path] )\n",
    "  args.extend( [\"--trained_checkpoint_prefix\", os.path.join(model_dir, best_checkpoint)] )\n",
    "  args.extend( [\"--output_directory\", output_dir] )\n",
    "  p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "  output, err = p.communicate()\n",
    "  print(err.decode())\n",
    "  print(output.decode())\n",
    "\n",
    "\n",
    "path_to_checkpoint = \"/MyDrive/rfcn-output/\"\n",
    "path_to_config = \"/content/detection/rfcn.config\"\n",
    "path_to_output = \"/MyDrive/rfcn-output/exported/\"\n",
    "\n",
    "export_inference_graph(path_to_checkpoint, path_to_config, path_to_output)\n",
    "\n",
    "### Just a local copy\n",
    "!mkdir /content/detection/exported/\n",
    "!cp -a /MyDrive/rfcn-output/exported/. /content/detection/exported/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7_Zl4OfR-ru"
   },
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsFxZWQIg57f"
   },
   "source": [
    "If we skipped the training, we need to download the trained weights (from [here](https://drive.google.com/open?id=1S_dpNJe9bFQU4jTA_YGuAC0QUpsvVUll)). Otherwise skip the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oos5jAkBg5P4"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "# This cell download the trained weights from the gDrive link\n",
    "\n",
    "gfileid=\"1S_dpNJe9bFQU4jTA_YGuAC0QUpsvVUll\"\n",
    "destination_dir=\"/content/detection/\"\n",
    "destination_path=\"${destination_dir}rfcn.zip\"\n",
    "\n",
    "curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${gfileid}\" > /dev/null\n",
    "curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${gfileid}\" -o ${destination_path}\n",
    "unzip ${destination_path}\n",
    "rm ${destination_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEFxo34fR95U"
   },
   "outputs": [],
   "source": [
    "from helpers.inference import detect\n",
    "\n",
    "# path to the exported frozen graph\n",
    "graph_path = \"/content/detection/exported\"\n",
    "\n",
    "# list of images to infer on\n",
    "images_path = [\"/content/detection/dataset/test-img-1.jpg\", \"/content/detection/dataset/test-img-2.jpg\"]\n",
    "\n",
    "# path to the label_map file containing the class names (\"car\", \"truck\", \"pedestrian\" etc.)\n",
    "label_path = \"/content/detection/dataset/label_map.pbtxt\"\n",
    "\n",
    "detections = detect( graph_path, label_path, images_path )\n",
    "#(boxes, scores, classes, num) = detections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHfpvPvAWmvi"
   },
   "source": [
    "Let's visualize the predicted boxes on the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBjSt3IHWkS1"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from utils import visualization_utils as vis_util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread( images_path[0] )\n",
    "(boxes, scores, classes, num) = detections[0]\n",
    "\n",
    "\n",
    "category_index = {1: {'id': 1, 'name': 'car'},\n",
    "                 2: {'id': 2, 'name': 'class 2'},\n",
    "                 3: {'id': 3, 'name': 'class 3'},\n",
    "                 4: {'id': 4, 'name': 'class 4'},\n",
    "                 5: {'id': 5, 'name': 'class 5'},\n",
    "                 6: {'id': 6, 'name': 'class 6'}}\n",
    "\n",
    "image = vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    np.squeeze(boxes),\n",
    "    np.squeeze(classes).astype(np.int32),\n",
    "    np.squeeze(scores),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    line_thickness=4,\n",
    "    min_score_thresh=0.50,\n",
    "    max_boxes_to_draw=100)\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.axis('off')\n",
    "img = plt.imshow( image )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJA1cN67EV3t"
   },
   "source": [
    "Next cell show how to generate the file for the MDP input from a directory containing all the frames of a video as images.  \n",
    "~3.3 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqAmUBawYs-H"
   },
   "outputs": [],
   "source": [
    "from helpers.inference import detect\n",
    "import cv2, numpy as np\n",
    "\n",
    "# Only boxes with confidence score > THRESHOLD are kept\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "# Path to the video directory\n",
    "input_path = \"/MyDrive/PATH_TO_VIDEO/\"\n",
    "output_path = \"/MyDrive/rfcn-mot.txt\"\n",
    "graph_path = \"/content/detection/exported\"\n",
    "label_path = \"/content/detection/dataset/label_map.pbtxt\"\n",
    "\n",
    "# List images\n",
    "images_path = [ os.path.join(input_path, f) for f in os.listdir(input_path) if not f.startswith(\".\")][0:100]\n",
    "\n",
    "print( \"Detecting on {} images\".format(len(images_path)) )\n",
    "detections = detect( graph_path, label_path, images_path )\n",
    "\n",
    "print( \"Done.\\nExporting to {} in MOT format\".format(output_path) )\n",
    "with open( output_path, 'w' ) as f:\n",
    "  # for each image\n",
    "  for frame, dets in enumerate(detections):\n",
    "    (boxes, scores, classes, num) = dets\n",
    "    \n",
    "    image = cv2.imread( images_path[frame] ) # does not actually read the image data\n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    indices = np.where( scores > THRESHOLD )\n",
    "    boxes = boxes[indices]\n",
    "    scores = scores[indices]\n",
    "    classes = classes[indices]\n",
    "\n",
    "    # for each box\n",
    "    for i in range(len(boxes)):\n",
    "      box = boxes[i]\n",
    "      entry = [frame+1, -1, int(box[1]*w), int(box[0]*h), int( (box[3]-box[1])*h ), int( (box[2]-box[0])*h ), scores[i], -1, -1, -1 ]\n",
    "      f.write( \",\".join(map(str, entry)) + '\\n' )\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDFs6EWKTa8m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RyU7K4tmjiDx",
    "V8qbk8Fnk21o",
    "tdDwTUe1viIC",
    "btmTTrS6_nuX",
    "jsActO4n9C_X",
    "WvqcJSSpPAOl",
    "e7_Zl4OfR-ru"
   ],
   "name": "Detection-tuto.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
